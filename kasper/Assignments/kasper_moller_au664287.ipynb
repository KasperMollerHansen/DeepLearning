{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Part 1\n",
    "\n",
    "**a: In your opinion, what were the most important turning points in the history of deep learning?**\n",
    "\n",
    "There have been many important turning points in the history of deep learning. From the development of the first artificial neuron in the 1940s to today, a lot has happened. \n",
    "To me personally, the most important turning points have been the advancements in visual recognition. \n",
    "This is a key moment where deep learning began to show a clear advantage over traditional machine learning.\n",
    "\n",
    "**b: Explain the ADAM optimizer.**\n",
    "\n",
    "The typical optimizer uses some form of gradient descent to find a minimum loss. Problems occur when there are local minima along this path. \n",
    "The algorithm might get stuck and never optimize for minimal loss. Momentum is a way to reduce this problem. The momentum algorithm remembers the direction of previous iterations and pushes in that direction. \n",
    "Another technique that accelerates convergence is by adjusting the learning rate. \n",
    "This is known as the adaptive gradient algorithm, where the learning rate becomes smaller over time as it's divided by the sum of all previous gradients.\n",
    "\n",
    "The ADAM optimizer combines both of these features, making it one of the fastest optimizers to converge and, therefore, quite convenient. However, studies have shown that standard SGD with momentum can perform better overall.\n",
    "\n",
    "**c: Assume data input is a single 30x40 pixel image. First layer is a convolutional layer with 5 filters, with kernel size 3x2, step size (1,1) and padding='valid'. What are the output dimensions?**\n",
    "\n",
    "Since the padding is valid, it means that we wont add a padding around the image. The step size is (1,1), so the kernel will only move one step at the time. We have 5 filters, whih means that there will be 5 dimensions. \n",
    "$$\n",
    "  \\text{Output Height} = \\frac{\\text{Input Height} - \\text{Kernel height}}{\\text{Stide Height}} + 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "  \\text{Output Width} = \\frac{\\text{Input Width} - \\text{Kernel Width}}{\\text{Stide Width}} + 1\n",
    "$$\n",
    "\n",
    "Following these equations, the output dimensions will be 28x39x5, since we have no padding.\n",
    "\n",
    "\n",
    "**d: Assuming ReLU activations and offsets, and that the last layer is softmax, how many parameters does this network have:**\n",
    "\n",
    "<img src=\"data\\diagram.png\" alt=\"image\" width=\"700\" height=\"400\">\n",
    "\n",
    "The inputer layer is 5 and we have 3 hidden layers of size 5 and an output layer of 3. The number of parameters will be:\n",
    "\n",
    "$$\n",
    "  \\text{Parameters} = (5 \\cdot 5 + 5) + (5 \\cdot 5 + 5) + (5 \\cdot 5 + 5) + (5 \\cdot 3 + 3) = 3 \\cdot 30 + 18 = 108\n",
    "$$\n",
    "\n",
    "**e: For a given minibatch, the targets are [1,4, 5, 8] and the network output is [0.1,4.4,0.2,10]. If the loss function is \"torch.nn.HuberLoss(reduction='mean', delta=1.0)\", what is the loss for this minibatch?**\n",
    "\n",
    "For a batch of size $N$, the unreduced loss can be described as:\n",
    "\n",
    "$$\n",
    "L=\\left\\{l_1, \\ldots, l_N\\right\\}^T\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "l_n= \\begin{cases}\\frac{1}{2}\\left(x_n-y_n\\right)^2, & \\text { if }\\left|x_n-y_n\\right|<\\delta \\\\ \\delta\\left(\\left|x_n-y_n\\right|-\\frac{1}{2}\\delta\\right), & \\text { otherwise }\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "If reduction is not none, then:\n",
    "\n",
    "$$\n",
    "\\ell(x, y)= \\begin{cases}\\operatorname{mean}(L), & \\text { if reduction }=\\text { 'mean' } \\\\ \\operatorname{sum}(L), & \\text { if reduction }=\\text { 'sum' }\\end{cases}\n",
    "$$\n",
    "\n",
    "This will give the result of:\n",
    "\n",
    "$$\n",
    "L = \\left\\{\\frac{1}{2}(1-0.1)^2,\\frac{1}{2}(4-4.4)^2, \\delta\\left(\\left|5-0.2\\right|-\\frac{1}{2}\\delta\\right), \\delta\\left(\\left|8-10\\right|-\\frac{1}{2}\\delta\\right)\\right\\}^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "L = \\left\\{0.405, 0.08, 4.3, 1.5\\right\\}^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ell(x, y)=\\frac{0.405 + 0.08 + 4.3 + 1.5}{4} = \\frac{6.285}{4} = 1.57125\n",
    "$$\n",
    "\n",
    "The loss of the minibatch will be 1.57125\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Writing a PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Andrena fulva': 0, 'Panurgus banksianus': 1, 'Lasioglossum punctatissimum': 2}\n"
     ]
    }
   ],
   "source": [
    "class InsectsDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with csv and image folder.\n",
    "            csv_file (string): Path to the csv file with filenames and species.\n",
    "            image_folder (string): Directory with images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.image_folder = image_folder\n",
    "        self.csv_path =  os.path.join(self.root_dir, csv_file)\n",
    "        self.insects_df = pd.read_csv(self.csv_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create a mapping from species name to integer labels\n",
    "        self.species_to_label = {species: idx for idx, species in enumerate(self.insects_df['species'].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.insects_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image file path\n",
    "        img_name = os.path.join(self.root_dir, self.image_folder, self.insects_df.iloc[idx, 2])  #'filename' is the third column\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # Get the species label\n",
    "        species = self.insects_df.iloc[idx, 1]  # assuming 'species' is the second column\n",
    "        label = self.species_to_label[species]\n",
    "        \n",
    "        # Apply transformations if needed\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((520, 520)), # Resizing the image to 520x520\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = InsectsDataset(csv_file='insects.csv',image_folder = \"Insects\", root_dir='data/', transform=transform)\n",
    "print(dataset.species_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# Set up the dataset.\n",
    "dataset = dataset\n",
    "\n",
    "# Set up the dataset.\n",
    "trainloader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "\n",
    "# get some images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "'''\n",
    "for i in range(2): #Run through 5 batches\n",
    "    images, labels = next(dataiter)\n",
    "    for image, label in zip(images,labels): # Run through all samples in a batch\n",
    "        plt.figure()\n",
    "        plt.imshow(np.transpose(image.numpy(), (1, 2, 0)))\n",
    "        plt.title(label)\n",
    "'''\n",
    "Works = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
